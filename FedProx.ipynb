{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xawNFFDpKTC-"
      },
      "outputs": [],
      "source": [
        "#Import libraries\n",
        "import tensorflow as tf\n",
        "import tensorflow_datasets as tfds\n",
        "import numpy as np\n",
        "from tensorflow.keras.datasets import mnist\n",
        "from sklearn.model_selection import KFold\n",
        "from tensorflow.keras.datasets import mnist\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Conv2D\n",
        "from tensorflow.keras.layers import MaxPooling2D\n",
        "from tensorflow.keras.layers import Dense\n",
        "from tensorflow.keras.layers import Flatten\n",
        "from tensorflow.keras.optimizers import SGD\n",
        "import random\n",
        "from numpy import linalg as LA"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PL2VLKfnQjc7"
      },
      "outputs": [],
      "source": [
        "def load_model(model_path):\n",
        "    model = Sequential()\n",
        "    model.add(Flatten(input_shape=(28, 28)))\n",
        "    model.add(Dense(128, activation='relu', kernel_initializer='he_uniform', kernel_regularizer=tf.keras.regularizers.l2(0.001)))\n",
        "    model.add(Dense(10, activation='softmax', kernel_regularizer=tf.keras.regularizers.l2(0.001)))\n",
        "\n",
        "    return model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HYzfgIf5QkDK"
      },
      "outputs": [],
      "source": [
        "# Load train and test dataset\n",
        "def load_dataset():\n",
        "    # load dataset\n",
        "    (trainX, trainY), (testX, testY) = mnist.load_data()\n",
        "    # reshape dataset to have a single channel\n",
        "    trainX = trainX.reshape((trainX.shape[0], 28, 28, 1))\n",
        "    testX = testX.reshape((testX.shape[0], 28, 28, 1))\n",
        "    # one hot encode target values\n",
        "    trainY = to_categorical(trainY)\n",
        "    testY = to_categorical(testY)\n",
        "\n",
        "    random_indices = np.random.choice(len(trainX), 10016, replace=False)\n",
        "\n",
        "    # Select the subset of data and labels\n",
        "    subset_X = trainX[random_indices]\n",
        "    subset_Y = trainY[random_indices]\n",
        "    return subset_X, subset_Y, testX, testY"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "I2o-jAqBQ5tF"
      },
      "outputs": [],
      "source": [
        "# scale pixels\n",
        "def prep_pixels(train, test):\n",
        " # convert from integers to floats\n",
        " train_norm = train.astype('float32')\n",
        " test_norm = test.astype('float32')\n",
        " # normalize to range 0-1\n",
        " train_norm = train_norm / 255.0\n",
        " test_norm = test_norm / 255.0\n",
        " # return normalized images\n",
        " return train_norm, test_norm"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mLZED4uzRXnR",
        "outputId": "a8e2b448-5921-4139-f3b3-2cf470ec164c"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/mnist.npz\n",
            "11490434/11490434 [==============================] - 0s 0us/step\n"
          ]
        }
      ],
      "source": [
        "trainX = []\n",
        "trainY = []\n",
        "for i in range (0,6):\n",
        "  temp1, temp2, testX, testY = load_dataset()\n",
        "  temp1, testX = prep_pixels(temp1, testX)\n",
        "  trainX.append(temp1)\n",
        "  trainY.append(temp2)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pxRrMxWDVXP6"
      },
      "outputs": [],
      "source": [
        "class ClientProx:\n",
        "    def __init__(self, trainX, trainY, testX,\n",
        "                 testY, batchSize, model, regRate, gamma,\n",
        "                 loss, metrics, lr, optim=tf.keras.optimizers.legacy.SGD()):\n",
        "\n",
        "        self.model = model\n",
        "        self.trainX = trainX\n",
        "        self.trainY = trainY\n",
        "        self.testX = testX\n",
        "        self.testY = testY\n",
        "        self.batchSize = batchSize\n",
        "        self.lr = float(lr)\n",
        "        self.losses = loss\n",
        "        self.metrics = metrics\n",
        "        self.optim = optim\n",
        "        self.optim.learning_rate = self.lr\n",
        "        self.regRate = regRate\n",
        "        self.gamma = gamma\n",
        "\n",
        "    def train(self, Global):\n",
        "        print('started')\n",
        "        self.model.compile(optimizer=self.optim,\n",
        "                           loss=self.losses, metrics=self.metrics)\n",
        "        self.model.set_weights(Global)\n",
        "        count = 0\n",
        "        while(self.condition(Global) and count  < 1000):\n",
        "          count = count + 1\n",
        "          self.model.fit(self.trainX, self.trainY, verbose=0, batch_size = self.batchSize)\n",
        "\n",
        "        weights = self.model.get_weights()\n",
        "        delta_weights = [(w - wt) for w, wt in zip(weights,Global)]\n",
        "\n",
        "        return delta_weights, len(self.trainX)\n",
        "\n",
        "    def condition(self,Global):\n",
        "        x = 0\n",
        "        weights = self.model.trainable_weights\n",
        "        h = self.calculate_loss(weights, Global)\n",
        "        globalH = self.calculate_loss(Global, Global)\n",
        "\n",
        "        return bool(h > self.gamma * globalH)\n",
        "\n",
        "    def calculate_loss(self, W , Wt):\n",
        "        dummy_model = load_model('')\n",
        "        dummy_model.set_weights(W)\n",
        "        weights = dummy_model.trainable_weights\n",
        "        with tf.GradientTape() as tape:\n",
        "          predictions = dummy_model(self.trainX)\n",
        "          loss = self.losses(self.trainY, predictions)\n",
        "\n",
        "        grad_local_model_loss = tape.gradient(loss, weights)\n",
        "        grad_regularization_term = [self.regRate * (w - wt) for w, wt in zip(weights, Wt)]\n",
        "        h = [w + reg for w, reg in zip(grad_local_model_loss, grad_regularization_term)]\n",
        "        h = [LA.norm(w) for w in h]\n",
        "        h = np.array(h)\n",
        "        h = LA.norm(h)\n",
        "        return h"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "v2zoVeLz0VMv"
      },
      "outputs": [],
      "source": [
        "class Server:\n",
        "  def __init__(self, global_lr, clients_num):\n",
        "    self.global_model = load_model(model_path = \" \")\n",
        "    self.global_model.compile(\n",
        "    optimizer=tf.keras.optimizers.SGD(0.001),\n",
        "    loss=tf.keras.losses.CategoricalCrossentropy(from_logits=True),\n",
        "    metrics=[tf.keras.metrics.CategoricalAccuracy()],\n",
        "    )\n",
        "    self.clients_num = clients_num\n",
        "\n",
        "  def initiate(self):\n",
        "    self.clients = []\n",
        "    optim = tf.keras.optimizers.legacy.SGD()\n",
        "    for i in range(0,self.clients_num):\n",
        "      self.clients.append(ClientProx(trainX[i], trainY[i], testX, testY, 32\n",
        "                                         ,load_model(\"\"), 0.1 , 0.4\n",
        "                                         ,tf.keras.losses.CategoricalCrossentropy(from_logits=True)\n",
        "                                         ,[tf.keras.metrics.CategoricalAccuracy()]\n",
        "                                         , 0.01,optim))\n",
        "\n",
        "  def train(self, rounds):\n",
        "      weights = self.global_model.get_weights()\n",
        "      for j in range(0,rounds):\n",
        "        for client in self.clients:\n",
        "             [delta_weights , num_val] = client.train(self.global_model.get_weights())\n",
        "             for i in range(0 , len(weights)):\n",
        "                  weights[i] = weights[i] + (delta_weights[i] * (1.0  /float(self.clients_num)))\n",
        "        self.global_model.set_weights(weights)\n",
        "        print(\"Global:\",self.global_model.evaluate(testX, testY),\"\\n\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "epZsvb2jByTM"
      },
      "outputs": [],
      "source": [
        "server = Server(1, 6)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DENgkRCPB0uz"
      },
      "outputs": [],
      "source": [
        "server.initiate()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true,
          "base_uri": "https://localhost:8080/"
        },
        "id": "57cekDxLB3SM",
        "outputId": "fa33c64a-8773-48f4-9fcf-fc46afea7301"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "started\n",
            "started\n",
            "started\n",
            "started\n",
            "started\n",
            "started\n",
            "313/313 [==============================] - 1s 2ms/step - loss: 1.1206 - categorical_accuracy: 0.8191\n",
            "Global: [1.1206109523773193, 0.819100022315979] \n",
            "\n",
            "started\n",
            "started\n",
            "started\n",
            "started\n",
            "started\n",
            "started\n",
            "313/313 [==============================] - 1s 2ms/step - loss: 0.6174 - categorical_accuracy: 0.9014\n",
            "Global: [0.6174463629722595, 0.9014000296592712] \n",
            "\n"
          ]
        }
      ],
      "source": [
        "server.train(2)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_f_wihBHZmXd"
      },
      "outputs": [],
      "source": [
        "  #bare bones SGD with scaffold updates using gradient tape (Similar to pytorch)\n",
        "\n",
        "  ##loss_fn = tf.keras.losses.CategoricalCrossentropy(from_logits=True)\n",
        "  ##optimizer = tf.keras.optimizers.SGD(learning_rate=1e-3)\n",
        "  ##train_acc_metric = tf.keras.metrics.CategoricalAccuracy()\n",
        "  ##val_acc_metric = tf.keras.metrics.CategoricalAccuracy()\n",
        "  ##for i in range(0,len(self.trainX)):\n",
        "  ## with tf.GradientTape() as tape:\n",
        "  ##    logits = self.model(self.trainX[i], training=True)\n",
        "  ##    loss_value = loss_fn(self.trainY[i], logits)\n",
        "  ## grads = tape.gradient(loss_value, self.model.trainable_weights)\n",
        "  ## for i in range (0 , len(Global)):\n",
        "  ##    grads[i] += 1e-3 * (C[i] - self.c[i])\n",
        "  ## optimizer.apply_gradients(zip(grads, self.model.trainable_weights))\n",
        "\n",
        "\n",
        "\n",
        "      ##val_logits = self.model(self.testX, training=False)\n",
        "      # Update val metrics\n",
        "  ##val_acc_metric.update_state(self.testY, val_logits)\n",
        "  ##val_acc = val_acc_metric.result()\n",
        "  ##print(\"Client : Validation acc: %.4f\" % (float(val_acc),))\n",
        "  ##val_acc_metric.reset_states()\n",
        "  ##results = self.model.evaluate(self.testX , self.testY, batch_size=128)"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}