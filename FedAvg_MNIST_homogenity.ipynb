{
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# FedAvg algorithm (Homogenous Data)\n",
        "\n",
        "The followng script contains the result of 3 server 60000 datapoints FSGD algorithm results.The training data for each of these clients is common and homogenous in classes."
      ],
      "metadata": {
        "id": "nsk_eikaXB4X"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FrzD3FFgwDk8"
      },
      "outputs": [],
      "source": [
        "import tensorflow as tf\n",
        "import tensorflow_datasets as tfds\n",
        "import numpy as np\n",
        "from tensorflow.keras.datasets import mnist"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Loading Data**\n",
        "\n",
        "The models train on an mnist dataset which are  grayscale images.\n",
        "\n",
        "The images are normalized on the pixel intensity range and reshaped into a singe vector of length 784."
      ],
      "metadata": {
        "id": "x0tDELwTX0VV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def FSGD(weights,config):\n",
        "    \"\"\"Performs Federated Average Stochastic Gradient Descent.\n",
        "\n",
        "    Args:\n",
        "        weights: A list of dictionaries containing \"weights\"\n",
        "                 and \"datapoints\" (nk)\n",
        "        config: A config file / dictionary generated by the\n",
        "                to_config() method\n",
        "\n",
        "    Returns:\n",
        "        new_mode: The final model to be saved.\n",
        "    \"\"\"\n",
        "\n",
        "    final_weights = []\n",
        "    for i in weights[0][\"weights\"]:\n",
        "        final_weights.append(np.zeros(shape = i.shape))\n",
        "    total = 0.0\n",
        "    for i in weights:\n",
        "      total += i[\"datapoints\"]\n",
        "    for i in range (0,len(weights)):\n",
        "        for j in range (0,len(weights[i][\"weights\"])):\n",
        "          final_weights[j] = np.add(final_weights[j], (weights[i][\"datapoints\"] / total) * weights[i][\"weights\"][j])\n",
        "    new_model = tf.keras.Sequential.from_config(config)\n",
        "    new_model.set_weights(final_weights)\n",
        "    return new_model"
      ],
      "metadata": {
        "id": "phA1stxaau_h"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import KFold\n",
        "from tensorflow.keras.datasets import mnist\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Conv2D\n",
        "from tensorflow.keras.layers import MaxPooling2D\n",
        "from tensorflow.keras.layers import Dense\n",
        "from tensorflow.keras.layers import Flatten\n",
        "from tensorflow.keras.optimizers import SGD"
      ],
      "metadata": {
        "id": "qOGT01ZEZ5JQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**The CNN Model**\n",
        "\n",
        "The model is a 2DCNN to 100 dense model used commonly for MNIST classification."
      ],
      "metadata": {
        "id": "Q0aBetPQ37IR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def define_model():\n",
        " model = Sequential()\n",
        " model.add(Conv2D(32, (3, 3), activation='relu', kernel_initializer='he_uniform', input_shape=(28, 28, 1)))\n",
        " model.add(MaxPooling2D((2, 2)))\n",
        " model.add(Flatten())\n",
        " model.add(Dense(100, activation='relu', kernel_initializer='he_uniform'))\n",
        " model.add(Dense(10, activation='softmax'))\n",
        " # compile model\n",
        " opt = SGD(learning_rate=0.01, momentum=0.9)\n",
        " model.compile(optimizer=opt, loss='categorical_crossentropy', metrics=['accuracy'])\n",
        " return model"
      ],
      "metadata": {
        "id": "dyhgThlERhsZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# load train and test dataset\n",
        "def load_dataset():\n",
        " # load dataset\n",
        " (trainX, trainY), (testX, testY) = mnist.load_data()\n",
        " # reshape dataset to have a single channel\n",
        " trainX = trainX.reshape((trainX.shape[0], 28, 28, 1))\n",
        " testX = testX.reshape((testX.shape[0], 28, 28, 1))\n",
        " # one hot encode target values\n",
        " trainY = to_categorical(trainY)\n",
        " testY = to_categorical(testY)\n",
        " return trainX, trainY, testX, testY"
      ],
      "metadata": {
        "id": "HZ2i_7zJRj1B"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# scale pixels\n",
        "def prep_pixels(train, test):\n",
        " # convert from integers to floats\n",
        " train_norm = train.astype('float32')\n",
        " test_norm = test.astype('float32')\n",
        " # normalize to range 0-1\n",
        " train_norm = train_norm / 255.0\n",
        " test_norm = test_norm / 255.0\n",
        " # return normalized images\n",
        " return train_norm, test_norm"
      ],
      "metadata": {
        "id": "3DIvFPevR2PD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# evaluate a model using k-fold cross-validation\n",
        "def evaluate_model(dataX, dataY,weights,n_folds=5):\n",
        " scores, histories = list(), list()\n",
        " models = []\n",
        " # prepare cross validation\n",
        " kfold = KFold(n_folds, shuffle=True, random_state=1)\n",
        " # enumerate splits\n",
        " for train_ix, test_ix in kfold.split(dataX):\n",
        "    d ={}\n",
        "    # define model\n",
        "    model = define_model()\n",
        "    model.set_weights(weights)\n",
        "    # select rows for train and test\n",
        "    trainX, trainY, testX, testY = dataX[train_ix], dataY[train_ix], dataX[test_ix], dataY[test_ix]\n",
        "    # fit model\n",
        "    history = model.fit(trainX, trainY, epochs=1, batch_size=32, validation_data=(testX, testY), verbose=0)\n",
        "    # evaluate model\n",
        "    _, acc = model.evaluate(testX, testY, verbose=0)\n",
        "    print('> %.3f' % (acc * 100.0))\n",
        "    # stores scores\n",
        "    scores.append(acc)\n",
        "    histories.append(history)\n",
        "    d[\"weights\"] = model.get_weights()\n",
        "    d[\"datapoints\"] = len(trainX)\n",
        "    models.append(d)\n",
        " return scores, histories ,models"
      ],
      "metadata": {
        "id": "By-5_jJUSivy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "trainX, trainY, testX, testY = load_dataset()\n",
        "# prepare pixel data\n",
        "trainX, testX = prep_pixels(trainX, testX)"
      ],
      "metadata": {
        "id": "snuHuzgSpezW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**FedAvg**\n",
        "\n",
        "This function is the main federated average algorithm which initializes the CNN model and runs the evaluate_model() method which trains 5 models on 5 unequal distributions of the data and returns the 5 models weights along with no. of datapoints then this list of weights is sent to the FSGD() mdethod which averages the weights ,this is then the updated model and this repeated \"rounds\" times."
      ],
      "metadata": {
        "id": "lRgzZmhK8rGB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def FedAvg(trainX, trainY, testX, testY,rounds = 10):\n",
        "    model = define_model()\n",
        "    for i in range(0,rounds):\n",
        "      d = {}\n",
        "      scores,histories,models = evaluate_model(trainX, trainY,model.get_weights())\n",
        "      model = FSGD(models,model.get_config())\n",
        "    return model\n"
      ],
      "metadata": {
        "id": "G6u5l4TipQOy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Result**\n",
        "\n",
        "The Federated averaging algorithms is run for 10 rounds where the local epochs is 1.(no. of clients = 5)\n",
        "\n",
        "We observer that every 5 observation the average accuracy increases showing that the quality of the starting weights of the final model keeps increasing for only 1 round the observed average model gives and accuracy of 49 percent andd gives an accuarcy of 98.9 percent after 10 rounds of updation"
      ],
      "metadata": {
        "id": "4BNAe7xb-Wro"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model = FedAvg(trainX, trainY, testX, testY,rounds = 10)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "C7OfML_Jhxg7",
        "outputId": "2c8a2b6b-0486-4b66-cb1a-970ed4a45761"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "> 97.283\n",
            "> 97.325\n",
            "> 97.083\n",
            "> 97.233\n",
            "> 97.675\n",
            "> 98.150\n",
            "> 97.800\n",
            "> 97.942\n",
            "> 98.342\n",
            "> 98.133\n",
            "> 98.550\n",
            "> 98.417\n",
            "> 98.325\n",
            "> 98.767\n",
            "> 98.842\n",
            "> 99.050\n",
            "> 99.217\n",
            "> 98.525\n",
            "> 99.142\n",
            "> 99.083\n",
            "> 99.383\n",
            "> 98.942\n",
            "> 99.125\n",
            "> 99.400\n",
            "> 99.283\n",
            "> 99.350\n",
            "> 99.467\n",
            "> 99.308\n",
            "> 99.417\n",
            "> 99.425\n",
            "> 99.392\n",
            "> 99.733\n",
            "> 99.617\n",
            "> 99.650\n",
            "> 99.658\n",
            "> 99.750\n",
            "> 99.725\n",
            "> 99.850\n",
            "> 99.742\n",
            "> 99.850\n",
            "> 99.842\n",
            "> 99.867\n",
            "> 99.917\n",
            "> 99.875\n",
            "> 99.758\n",
            "> 99.933\n",
            "> 99.967\n",
            "> 99.900\n",
            "> 99.958\n",
            "> 99.883\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/backend.py:5612: UserWarning: \"`sparse_categorical_crossentropy` received `from_logits=True`, but the `output` argument was produced by a Softmax activation and thus does not represent logits. Was this intended?\n",
            "  output, from_logits = _get_logits(\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "ValueError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-37-3b921ea08fe6>\u001b[0m in \u001b[0;36m<cell line: 7>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0mmetrics\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkeras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmetrics\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mSparseCategoricalAccuracy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m     )\n\u001b[0;32m----> 7\u001b[0;31m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mevaluate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtestX\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mtestY\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/keras/utils/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     68\u001b[0m             \u001b[0;31m# To get the full stack trace, call:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     69\u001b[0m             \u001b[0;31m# `tf.debugging.disable_traceback_filtering()`\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 70\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwith_traceback\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfiltered_tb\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     71\u001b[0m         \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     72\u001b[0m             \u001b[0;32mdel\u001b[0m \u001b[0mfiltered_tb\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mtf__test_function\u001b[0;34m(iterator)\u001b[0m\n\u001b[1;32m     13\u001b[0m                 \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m                     \u001b[0mdo_return\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 15\u001b[0;31m                     \u001b[0mretval_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mag__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconverted_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mag__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mld\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstep_function\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mag__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mld\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mag__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mld\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfscope\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     16\u001b[0m                 \u001b[0;32mexcept\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m                     \u001b[0mdo_return\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mValueError\u001b[0m: in user code:\n\n    File \"/usr/local/lib/python3.10/dist-packages/keras/engine/training.py\", line 1852, in test_function  *\n        return step_function(self, iterator)\n    File \"/usr/local/lib/python3.10/dist-packages/keras/engine/training.py\", line 1836, in step_function  **\n        outputs = model.distribute_strategy.run(run_step, args=(data,))\n    File \"/usr/local/lib/python3.10/dist-packages/keras/engine/training.py\", line 1824, in run_step  **\n        outputs = model.test_step(data)\n    File \"/usr/local/lib/python3.10/dist-packages/keras/engine/training.py\", line 1791, in test_step\n        return self.compute_metrics(x, y, y_pred, sample_weight)\n    File \"/usr/local/lib/python3.10/dist-packages/keras/engine/training.py\", line 1149, in compute_metrics\n        self.compiled_metrics.update_state(y, y_pred, sample_weight)\n    File \"/usr/local/lib/python3.10/dist-packages/keras/engine/compile_utils.py\", line 605, in update_state\n        metric_obj.update_state(y_t, y_p, sample_weight=mask)\n    File \"/usr/local/lib/python3.10/dist-packages/keras/utils/metrics_utils.py\", line 77, in decorated\n        update_op = update_state_fn(*args, **kwargs)\n    File \"/usr/local/lib/python3.10/dist-packages/keras/metrics/base_metric.py\", line 140, in update_state_fn\n        return ag_update_state(*args, **kwargs)\n    File \"/usr/local/lib/python3.10/dist-packages/keras/metrics/base_metric.py\", line 691, in update_state  **\n        matches = ag_fn(y_true, y_pred, **self._fn_kwargs)\n    File \"/usr/local/lib/python3.10/dist-packages/keras/utils/metrics_utils.py\", line 963, in sparse_categorical_matches  **\n        y_true = tf.squeeze(y_true, [-1])\n\n    ValueError: Can not squeeze dim[1], expected a dimension of 1, got 10 for '{{node Squeeze}} = Squeeze[T=DT_FLOAT, squeeze_dims=[-1]](IteratorGetNext:1)' with input shapes: [?,10].\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "opt = SGD(learning_rate=0.01, momentum=0.9)\n",
        "model.compile(optimizer=opt, loss='categorical_crossentropy', metrics=['accuracy'])"
      ],
      "metadata": {
        "id": "GcTvIXfK3DAB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.evaluate(testX,testY)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jpXJX2cU3Ehh",
        "outputId": "3409dde4-8a2c-4cd8-e4fc-e122d5486c93"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "313/313 [==============================] - 4s 11ms/step - loss: 0.0376 - accuracy: 0.9893\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[0.03756684064865112, 0.989300012588501]"
            ]
          },
          "metadata": {},
          "execution_count": 39
        }
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}